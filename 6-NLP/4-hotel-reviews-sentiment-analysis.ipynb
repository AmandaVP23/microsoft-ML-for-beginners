{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbe20912",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Operations\n",
    "Apply sentiment analysis to the review columns and save the results in a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84bf2590",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/amanda.vieira/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/amanda.vieira/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import nltk as nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the filtered hotel reviews from csv\n",
    "df = pd.read_csv('./Hotel_Reviews_Filtered.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1503e2e5",
   "metadata": {},
   "source": [
    "If you were to run Sentiment Analysis on the Negative and Positive review columns, it could take a long time. Tested on a powerful test laptop with fast CPU,it took 12 - 14 minutes depending on which sentiment library was used. That's a (relatively) long time, so worth investigating if that can be speeded up.\n",
    "\n",
    "Removing stop words, or common English words that do not change the sentiment of a sentence, is the first step. By removing them, the sentiment analysis should run faster, but not be less accurate (as the stop words do not affect sentiment, but they do slow down the analysis).\n",
    "\n",
    "The longest negative review was 395 words, but after removing the stop words, it is 195 words.\n",
    "\n",
    "Removing the stop words is also a fast operation, removing the stop words from 2 review columns over 515,000 rows took 3.3 seconds on the test device. The relative shortness of the operation means that if it improves the sentiment analysis time, then it is worth doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6cc84e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "cache = set(stopwords.words(\"english\"))\n",
    "\n",
    "def remove_stopwords(review):\n",
    "    text = \" \".join([word for word in review.split() if word in cache])\n",
    "    return text\n",
    "\n",
    "df.Negative_Review = df.Negative_Review.apply(remove_stopwords)\n",
    "df.Positive_Review = df.Positive_Review.apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1d07e5",
   "metadata": {},
   "source": [
    "## Performing sentiment analysis\n",
    "\n",
    "Calculate the sentiment analysis for both negative and positive review columns, and store the result in 2 new columns.\n",
    "\n",
    "The test of the sentiment will be to compare it to the reviewer's score for the same review. For instance, if the sentiment thinks the negative review had a sentiment of 1 (extremely positive sentiment) and a positive review sentiment of 1, but the reviewer gave the hotel the lowest score possible, then either the review text doesn't match the score, or the sentiment analyser could not recognize the sentiment correctly. You should expect some sentiment scores to be completely wrong, and often that will be explainable, e.g. the review could be extremely sarcastic \"Of course I LOVED sleeping in a room with no heating\" and the sentiment analyser thinks that's positive sentiment, even though a human reading it would know it was sarcasm.\n",
    "\n",
    "NLTK supplies different sentiment analyzers to learn with, and you can substitute them and see if the sentiment is more or less accurate. The VADER sentiment analysis is used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f50c91df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the vader sentiment analyser (there are others in NLTK you can try too)\n",
    "vader_sentiment = SentimentIntensityAnalyzer()\n",
    "\n",
    "# There are 3 possibilities of input for a review:\n",
    "# It could be \"No Negative\", in which case return 0\n",
    "# It could be \"No Positive\", in which case, return 0\n",
    "# It could be a review, in which case calculate the sentiment\n",
    "\n",
    "def calc_sentiment(review):\n",
    "    if review == \"No Negative\" or review == \"No Positive\":\n",
    "        return 0\n",
    "    return vader_sentiment.polarity_scores(review)[\"compound\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69df23d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating sentiment columns for both positive and negative reviews\n",
      "Calculating sentiment took 23.67 seconds\n"
     ]
    }
   ],
   "source": [
    "# Add a negative sentiment and positive sentiment column\n",
    "print('Calculating sentiment columns for both positive and negative reviews')\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "df['Negative_Sentiment'] = df.Negative_Review.apply(calc_sentiment)\n",
    "df['Positive_Sentiment'] = df.Positive_Review.apply(calc_sentiment)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print('Calculating sentiment took ' + str(round(end - start, 2)) + ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5307f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Negative_Review  Negative_Sentiment\n",
      "512114  it s not at all the don t how they them the a ...             -0.9776\n",
      "155157  the was not as the was and the were it most wa...             -0.9559\n",
      "226751  is and there was on the this should be but and...             -0.9559\n",
      "252171  itself with some of the more and up when you i...             -0.9468\n",
      "267388  this for the and the is but which an to with t...             -0.9430\n",
      "...                                                   ...                 ...\n",
      "176261  didn t the on my to the when hadn t out the fo...              0.9077\n",
      "5883    was but the are the of so the won t have to th...              0.9175\n",
      "172285  was not in no in no no and it an to didn t the...              0.9235\n",
      "63987   in and you have to for you once was not the ha...              0.9726\n",
      "161675  we in this we them on it but after few it was ...              0.9743\n",
      "\n",
      "[515738 rows x 2 columns]\n",
      "                                          Positive_Review  Positive_Sentiment\n",
      "69089   have at this over has had had a and the are ov...             -0.9430\n",
      "373561  was just a was on was a there before but the n...             -0.9413\n",
      "199286  very but very no no for the no out no on just and             -0.9386\n",
      "472800                      was very has no a no no no no             -0.8858\n",
      "417011  was when we there at ve that before but was so...             -0.8664\n",
      "...                                                   ...                 ...\n",
      "473139  was and the was but don t to there is of about...              0.7556\n",
      "163346  what my on this s by a and they are so of the ...              0.8126\n",
      "178754  the at your above and to my was to and the tha...              0.9022\n",
      "394254  to which was the of my by which to s are and i...              0.9022\n",
      "180755  an to the by to don t a few from to where you ...              0.9168\n",
      "\n",
      "[515738 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Print the results and see it the sentiment matches the review\n",
    "df = df.sort_values(by=[\"Negative_Sentiment\"], ascending=True)\n",
    "print(df[[\"Negative_Review\", \"Negative_Sentiment\"]])\n",
    "\n",
    "df = df.sort_values(by=[\"Positive_Sentiment\"], ascending=True)\n",
    "print(df[[\"Positive_Review\", \"Positive_Sentiment\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219b939c",
   "metadata": {},
   "source": [
    "## Save the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b4d22b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to Hotel_Reviews_NLP.csv\n"
     ]
    }
   ],
   "source": [
    "# Reorder the columns (This is cosmetic, but to make it easier to explore the data later)\n",
    "df = df.reindex([\"Hotel_Name\", \"Hotel_Address\", \"Total_Number_of_Reviews\", \"Average_Score\", \"Reviewer_Score\", \"Negative_Sentiment\", \"Positive_Sentiment\", \"Reviewer_Nationality\", \"Leisure_trip\", \"Couple\", \"Solo_traveler\", \"Business_trip\", \"Group\", \"Family_with_young_children\", \"Family_with_older_children\", \"With_a_pet\", \"Negative_Review\", \"Positive_Review\"], axis=1)\n",
    "\n",
    "print('Saving results to Hotel_Reviews_NLP.csv')\n",
    "df.to_csv('Hotel_Reviews_NLP.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
